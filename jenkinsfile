def setupMavenSettings() {
    script {
        withCredentials([file(credentialsId: 'maven-artifactory-settings', variable: 'MVN_SETTINGS_PATH')]) {
            sh script: '''
                mkdir -p ~/.m2
                cp -f $MVN_SETTINGS_PATH ~/.m2/settings.xml
            ''',
               label: 'setup maven settings'
        }
    }
}

def markBvtAsFail(artifactName, version) {
    script {
        withCredentials(
                [usernamePassword(
                        credentialsId: 'repo.cnc.imply.io',
                        usernameVariable: 'ARTIFACTORY_USER',
                        passwordVariable: 'ARTIFACTORY_PASSWORD'
                )]
        ) {
            def UPDATE_PROPS_URL = "https://repo.cnc.imply.io/artifactory/api/metadata/tgz-local/${artifactName}/${artifactName}-${version}.tar.gz"
            sh(script: """
                curl -u "${ARTIFACTORY_USER}":"${ARTIFACTORY_PASSWORD}" --location --request PATCH "${UPDATE_PROPS_URL}" \
                --header 'Content-Type: application/json' \
                --data-raw '{
                    "props":{
                        "BVT": "Fail"
                    }
                }'"""
            )
        }
    }
}

def mavenInstall() {
    setupMavenSettings()
    sh script: '''
        ${MVN} clean install -q -ff -pl \'!distribution\' ${MAVEN_SKIP} ${MAVEN_SKIP_TESTS} -T1C
        ${MVN} install -q -ff -pl \'distribution\' ${MAVEN_SKIP} ${MAVEN_SKIP_TESTS}
    ''',
       label: 'mvn install'
}

def dockerCleanup() {
    sh  script: 'docker system prune -f -a --volumes || true',
        label: 'cleanup docker data'
}

def mavenDockerBackup() {
    rtDockerPull(
            serverId: "${RT_SERVER_ID}",
            image: "${RT_DOCKER_REPOSITORY_PREFIX}/${CURRENT_DOCKER_IMAGE}",
            sourceRepo: 'docker-local'
    )
    sh script: '''#!/bin/bash -e
        TEMP_DIR=$(mktemp -d)
        git status --ignored --porcelain | \
            grep -E '^\\!\\!' | sed 's|/$||' | awk -F'\\!\\! ' '{print $2}' | grep -v -E '^web-console' | \
        while read mvnresult; do mkdir -p ${TEMP_DIR}/$(dirname -- $mvnresult); cp -R $mvnresult ${TEMP_DIR}/$mvnresult; done
        tar -czf /tmp/mvnresult.tar.gz -C ${TEMP_DIR} .
        tar -czf /tmp/m2repository.tar.gz -C ~/.m2 repository
        rm -rf ${TEMP_DIR}

        cd /tmp
        echo "FROM ${RT_DOCKER_REPOSITORY_PREFIX}/${CURRENT_DOCKER_IMAGE}" >> Dockerfile
        echo "COPY m2repository.tar.gz /tmp/m2repository.tar.gz" >> Dockerfile
        echo "COPY mvnresult.tar.gz /tmp/mvnresult.tar.gz" >> Dockerfile
        docker build -t ${RT_DOCKER_REPOSITORY_PREFIX}/${CURRENT_DOCKER_IMAGE}-${DOCKER_TAG} .
    ''',
       label: 'build temporary docker image for the build'
    rtDockerPush(
            serverId: "${RT_SERVER_ID}",
            image: "${RT_DOCKER_REPOSITORY_PREFIX}/${CURRENT_DOCKER_IMAGE}-${DOCKER_TAG}",
            targetRepo: 'docker-local'
    )
}

def mavenCacheRestore() {
    setupMavenSettings()
    sh script: '''#!/bin/bash -e
        tar -xzf /tmp/mvnresult.tar.gz --no-same-owner --no-overwrite-dir -C ./
        mkdir -p ~/.m2
        tar -xzf /tmp/m2repository.tar.gz --no-same-owner --no-overwrite-dir -C ~/.m2/
    ''',
       label: 'restore build cache'
}

def prepareIfconfig() {
    sh script: '''
        echo -e '#!/bin/bash\nPATH=/sbin:$PATH exec ifconfig eth0 $@' > /usr/bin/ifconfig
        chmod +x /usr/bin/ifconfig
        hash -r
    ''',
       label: "prepare ifconfig"
}

def getInstanceId() {
    sh script: '''#!/bin/bash -x
        curl -s http://169.254.169.254/latest/meta-data/instance-id
    ''',
       label: 'print instance id'
}

def buildArtifacts(stageName) {
    script {
        def stageArtifactsDirPath = "stage_${stageName.replaceAll(~/[^A-Za-z0-9_-]/,'_')}"
        withEnv(["stageArtifactsDirPath=${stageArtifactsDirPath}"]) {
            // copy logs
            sh script: '''#!/bin/bash -x
                mkdir -p ${stageArtifactsDirPath}

                shopt -s globstar

                urlencode_path() {
                    python -c 'import urllib, sys; print urllib.quote(sys.argv[1], sys.argv[2])' "$1" "/"
                }

                copy_files_by_pattern() {
                    if  ls ${1}; then
                        for fname in ${1}; do
                            fname_root=$(echo "${fname}" | cut -d "/" -f1)
                            if ! [[ "$fname_root" = "${2}" ]]; then
                                if [[ -f "$fname" ]]; then
                                    dest=${2}/$(urlencode_path "${fname}")
                                    mkdir -p $(dirname -- "$dest")
                                    cp "$fname" "$dest"
                                fi
                            fi
                        done
                    fi
                }

                if [ -d ~/shared ]; then
                    artifacts_path=$(pwd)/${stageArtifactsDirPath}
                    pushd ~/shared
                    copy_files_by_pattern 'logs/**' $artifacts_path
                    copy_files_by_pattern 'tasklogs/**' $artifacts_path
                    popd
                fi

                # copy dockerd logs
                artifacts_path=$(pwd)/${stageArtifactsDirPath}
                pushd /var/tmp
                copy_files_by_pattern 'dockerd.log' $artifacts_path
                popd

                # copy test reports
                copy_files_by_pattern '**/target/surefire-reports/*.xml' ${stageArtifactsDirPath}
                copy_files_by_pattern '**/target/failsafe-reports/*.xml' ${stageArtifactsDirPath}

                # copy top-level jacoco reports
                copy_files_by_pattern '**/target/*.exec' ${stageArtifactsDirPath}
                copy_files_by_pattern '**/jacoco/*.html' ${stageArtifactsDirPath}
                copy_files_by_pattern '**/jacoco/*.xml' ${stageArtifactsDirPath}
                copy_files_by_pattern '**/jacoco/*.csv' ${stageArtifactsDirPath}
                copy_files_by_pattern '**/jacoco/jacoco-resources/*' ${stageArtifactsDirPath}
                # copy detailed jacoco reports
                copy_files_by_pattern '**/jacoco/**/*.html' ${stageArtifactsDirPath}
                copy_files_by_pattern '**/jacoco/**/*.xml' ${stageArtifactsDirPath}
                copy_files_by_pattern '**/jacoco/**/*.csv' ${stageArtifactsDirPath}
                # inspection results
                copy_files_by_pattern 'inspection-results/*.xml' ${stageArtifactsDirPath}
            '''
        }
        // fixate artifacts
        archiveArtifacts artifacts: "${stageArtifactsDirPath}/**", allowEmptyArchive: true
        // cleanup tmp artifacts dir
        sh script: "rm -rf ${stageArtifactsDirPath}"
    }
}

def resetWs() {
    sh script: "git clean -fdx", label: "Clean up everything but files from git"
}

def isEligibleToNotify() {
    return  !env.CHANGE_ID \
            && (env.BRANCH_NAME ==~ env.ACTIVE_DEV_BRANCH_REGEX || env.BRANCH_NAME ==~ (env.RELEASE_BRANCH_PREFIX_REGEX+env.RELEASE_BRANCH_SUFFIX_REGEX))
}

def implyQueryIntegrationTests(jvmRuntimeOpt) {
    mavenCacheRestore()
    prepareIfconfig()
    getInstanceId()
    script {
        retry(2) {
            try {
                sh script: """
                    \${MVN} -pl integration-tests process-resources && \${MVN} verify -Pintegration-tests-imply -pl integration-tests-imply \
                    -Dgroups=query \
                    -Dit.indexer=middleManager \
                    ${jvmRuntimeOpt} \
                    -Ddruid.test.config.extraDatasourceNameSuffix="" \
                    -Doverride.config.path=../../integration-tests-imply/docker/environment-configs/test-groups/prepopulated-data \
                    -ff \${MAVEN_SKIP} -Djacoco.skip=true
                """,
                   label: "imply query integration tests with ${jvmRuntimeOpt}"
            } finally {
                dockerCleanup()
            }
        }
    }
}

def implyKeycloakSecurityIntegrationTests(jvmRuntimeOpt) {
    mavenInstall()
    prepareIfconfig()
    getInstanceId()
    script {
        retry(3) {
            try {
                sh script: """
                    \${MVN} -pl integration-tests process-resources && ${MVN} verify -Pintegration-tests-imply -pl integration-tests-imply \
                    -Dgroups=keycloak-security \
                    -Dit.indexer=middleManager \
                    -Doverride.config.path=../../integration-tests-imply/docker/environment-configs/test-groups/keycloak-security \
                    ${jvmRuntimeOpt} \
                    -ff \${MAVEN_SKIP} -Djacoco.skip=true
                """,
                   label: "imply keycloak security integration tests with ${jvmRuntimeOpt}"
            } finally {
                dockerCleanup()
            }
        }
    }
}

def implyVirtualSegmentsIntegrationTests(jvmRuntimeOpt) {
    mavenInstall()
    prepareIfconfig()
    getInstanceId()
    script {
        retry(2) {
            try {
                sh script: """
                    \${MVN} -pl integration-tests process-resources && ${MVN} verify -Pintegration-tests-imply -pl integration-tests-imply \
                    -Dgroups=virtual-segments \
                    -Dit.indexer=middleManager \
                    -Doverride.config.path=../../integration-tests-imply/docker/environment-configs/test-groups/virtual-segments \
                    ${jvmRuntimeOpt} \
                    -ff \${MAVEN_SKIP} -Djacoco.skip=true
                """,
                   label: "imply cold tier integration tests with ${jvmRuntimeOpt}"
            } finally {
                dockerCleanup()
            }
        }
    }
}

def implyAsyncDownloadIntegrationTests(jvmRuntimeOpt) {
    mavenCacheRestore()
    prepareIfconfig()
    getInstanceId()
    script {
        retry(2) {
            try {
                sh script: """
                    \${MVN} -pl integration-tests process-resources && ${MVN} verify -Pintegration-tests-imply -pl integration-tests-imply \
                    -Dgroups=async-download \
                    -Dit.indexer=middleManager \
                    -Doverride.config.path=../../integration-tests-imply/docker/environment-configs/test-groups/async-download \
                    ${jvmRuntimeOpt} \
                    -ff \${MAVEN_SKIP} -Djacoco.skip=true
                """,
                   label: "imply async query result download integration tests with ${jvmRuntimeOpt}"
            } finally {
                dockerCleanup()
            }
        }
    }
}

def implyS3Tests(jvmRuntimeOpt) {
    mavenCacheRestore()
    prepareIfconfig()
    getInstanceId()
    script {
        withCredentials([[$class: 'AmazonWebServicesCredentialsBinding', accessKeyVariable: 'AWS_ACCESS_KEY_ID', credentialsId: 'aws', secretKeyVariable: 'AWS_SECRET_ACCESS_KEY']]) {
            def cloudpath = UUID.randomUUID().toString()
            writeFile   file: "jenkins/s3-config",
                        text: "druid_storage_type=s3\ndruid_storage_bucket=druid-qa\ndruid_storage_baseKey=${cloudpath}\ndruid_s3_accessKey=${AWS_ACCESS_KEY_ID}\ndruid_s3_secretKey=${AWS_SECRET_ACCESS_KEY}\nAWS_REGION=us-east-1\ndruid_extensions_loadList=[\"mysql-metadata-storage\",\"druid-basic-security\",\"simple-client-sslcontext\",\"druid-testing-tools\",\"druid-lookups-cached-global\",\"druid-histogram\",\"druid-datasketches\",\"imply-sql-async\",\"druid-s3-extensions\"]\ndruid_query_async_storage_type=s3\ndruid_query_async_storage_s3_bucket=druid-qa\ndruid_query_async_storage_s3_prefix=${cloudpath}/async-test/\ndruid_query_async_storage_s3_tempDir=/shared/async-tmp-results\ndruid_metadata_storage_type=mysql\ndruid_metadata_storage_connector_connectURI=jdbc:mysql://druid-metadata-storage/druid\ndruid_metadata_storage_connector_user=druid\ndruid_metadata_storage_connector_password=diurd"
            retry(2) {
                try {
                    sh script: """
                        \${MVN} -pl integration-tests process-resources && ${MVN} verify -P integration-tests-imply -pl integration-tests-imply \
                        -Dgroups=imply-s3 \
                        -Doverride.config.path=\${WORKSPACE}/jenkins/s3-config \
                        ${jvmRuntimeOpt} \
                        -Ddruid.test.config.cloudBucket=druid-qa \
                        -Ddruid.test.config.cloudPath=${cloudpath}/ \
                        -ff \${MAVEN_SKIP} -Djacoco.skip=true
                    """,
                       label: "imply-s3 with ${jvmRuntimeOpt}"
                }
                finally {
                    dockerCleanup()
                }
            }
        }
    }
}

def s3DeepStorageTests(jvmRuntimeOpt) {
    mavenCacheRestore()
    prepareIfconfig()
    getInstanceId()
    script {
        withCredentials([[$class: 'AmazonWebServicesCredentialsBinding', accessKeyVariable: 'AWS_ACCESS_KEY_ID', credentialsId: 'aws', secretKeyVariable: 'AWS_SECRET_ACCESS_KEY']]) {
            def cloudpath = UUID.randomUUID().toString()
            writeFile   file: "jenkins/s3-config",
                        text: "druid_storage_type=s3\n" +
                              "druid_storage_bucket=druid-qa\n" +
                              "druid_storage_baseKey=${cloudpath}\n" +
                              "druid_s3_accessKey=${AWS_ACCESS_KEY_ID}\n" +
                              "druid_s3_secretKey=${AWS_SECRET_ACCESS_KEY}\n" +
                              "AWS_REGION=us-east-1\n" +
                              "druid_extensions_loadList=[\"mysql-metadata-storage\",\"druid-basic-security\",\"simple-client-sslcontext\",\"druid-testing-tools\",\"druid-lookups-cached-global\",\"druid-histogram\",\"druid-datasketches\",\"druid-hdfs-storage\",\"druid-s3-extensions\",\"druid-parquet-extensions\",\"druid-avro-extensions\",\"druid-protobuf-extensions\",\"druid-orc-extensions\",\"druid-kafka-indexing-service\"]"
            retry(2) {
                try {
                    sh script: """
                        aws s3 sync \
                        ./integration-tests/src/test/resources/data/batch_index/json/ s3://druid-qa/${cloudpath} \
                        --exclude "*" --include "wikipedia_index_data*.json"
                    """,
                       label: "uploading data to bucket"
                    sh script: """
                        \${MVN} verify -P integration-tests -pl integration-tests \
                        -Dgroups=s3-deep-storage \
                        -Doverride.config.path=\${WORKSPACE}/jenkins/s3-config \
                        ${jvmRuntimeOpt} \
                        -Ddruid.test.config.cloudBucket=druid-qa \
                        -Ddruid.test.config.cloudPath=${cloudpath}/ \
                        -Ddocker.build.hadoop=true \
                        -Dstart.hadoop.docker=true \
                        -ff \${MAVEN_SKIP} -Djacoco.skip=true
                    """,
                       label: "s3-deep-storage with ${jvmRuntimeOpt}"
                }
                finally {
                    dockerCleanup()
                    sh script: "aws s3 rm s3://druid-qa/${cloudpath} --recursive"
                }
            }
        }
    }
}

def kinesisDeepStorageTests(jvmRuntimeOpt) {
    mavenCacheRestore()
    prepareIfconfig()
    getInstanceId()
    script {
        withCredentials([[$class: 'AmazonWebServicesCredentialsBinding', accessKeyVariable: 'AWS_ACCESS_KEY_ID', credentialsId:  'aws', secretKeyVariable: 'AWS_SECRET_ACCESS_KEY']]) {
            lock('awsResource') {
                writeFile   file: "jenkins/kinesis-config",
                            text: "druid_kinesis_accessKey=${AWS_ACCESS_KEY_ID}\ndruid_kinesis_secretKey=${AWS_SECRET_ACCESS_KEY}\nAWS_REGION=us-east-1\ndruid_extensions_loadList=[\"mysql-metadata-storage\",\"druid-basic-security\",\"simple-client-sslcontext\",\"druid-testing-tools\",\"druid-lookups-cached-global\",\"druid-histogram\",\"druid-datasketches\",\"druid-kinesis-indexing-service\"]"
                retry(2) {
                    try {
                        sh script: """
                            \${MVN} verify -P integration-tests -pl integration-tests \
                            -Dgroups=kinesis-index \
                            -Doverride.config.path=\${WORKSPACE}/jenkins/kinesis-config \
                            ${jvmRuntimeOpt} \
                            -Ddruid.test.config.streamEndpoint=kinesis.us-east-1.amazonaws.com \
                            -Ddocker.build.hadoop=true \
                            -Dstart.hadoop.docker=true \
                            -ff \${MAVEN_SKIP} -Djacoco.skip=true
                        """,
                           label: "kinesis-deep-storage with ${jvmRuntimeOpt}"
                    } finally {
                        dockerCleanup()
                    }
                }
            }
        }
    }
}

def azureDeepStorageTests(jvmRuntimeOpt) {
    mavenCacheRestore()
    prepareIfconfig()
    getInstanceId()
    script {
        withCredentials([usernamePassword(credentialsId: 'azure_credentials', usernameVariable: 'AZURE_ACCOUNT', passwordVariable: 'AZURE_KEY')]) {
            def containerName = UUID.randomUUID().toString()
            writeFile   file: "jenkins/azure-config",
                        text: "druid_storage_type=azure\n" +
                              "druid_azure_account=${AZURE_ACCOUNT}\n" +
                              "druid_azure_key=${AZURE_KEY}\n" +
                              "druid_azure_container=${containerName}\n" +
                              "druid_extensions_loadList=[\"mysql-metadata-storage\",\"druid-basic-security\",\"simple-client-sslcontext\",\"druid-testing-tools\",\"druid-lookups-cached-global\",\"druid-histogram\",\"druid-datasketches\",\"druid-hdfs-storage\",\"druid-azure-extensions\",\"druid-parquet-extensions\",\"druid-avro-extensions\",\"druid-protobuf-extensions\",\"druid-orc-extensions\",\"druid-kafka-indexing-service\"]"
            retry(2) {
                try {
                    sh script: """
                        az storage container create -n ${containerName} \
                        --public-access blob \
                        --account-name \${AZURE_ACCOUNT} --account-key \${AZURE_KEY}
                    """,
                       label: "creating storage container"
                    sh script: """
                        az storage blob upload-batch \
                        --account-name \${AZURE_ACCOUNT} --account-key \${AZURE_KEY} \
                        -d ${containerName} \
                        --source ./integration-tests/src/test/resources/data/batch_index/json/ --pattern "wikipedia_index_data*.json"
                    """,
                       label: "uploading data to storage container"
                    sh script: """
                        \${MVN} verify -P integration-tests -pl integration-tests \
                        -Dgroups=azure-deep-storage \
                        -Doverride.config.path=\${WORKSPACE}/jenkins/azure-config \
                        ${jvmRuntimeOpt} \
                        -Ddruid.test.config.cloudBucket=${containerName} \
                        -Ddruid.test.config.cloudPath= \
                        -Ddocker.build.hadoop=true \
                        -Dstart.hadoop.docker=true \
                        -ff \${MAVEN_SKIP} -Djacoco.skip=true
                    """,
                       label: "azure-deep-storage with ${jvmRuntimeOpt}"
                }
                finally {
                    dockerCleanup()
                    sh script: """
                        az storage container delete -n ${containerName}\
                        --account-name \${AZURE_ACCOUNT} --account-key \${AZURE_KEY}
                    """
                }
            }
        }
    }
}

def gcsDeepStorageTests(jvmRuntimeOpt) {
    mavenCacheRestore()
    prepareIfconfig()
    getInstanceId()
    script {
        withCredentials([file(credentialsId: 'gcs-bucket-qa', variable: 'GC_KEY')]) {
            def cloudpath = "gcs-test-${UUID.randomUUID().toString()}/"
            def bucket = "imply-qa-testing"
            writeFile   file: "jenkins/gcs-config",
                        text: "druid_storage_type=google\ndruid_google_bucket=${bucket}\ndruid_google_prefix=${cloudpath}\ndruid_extensions_loadList=[\"mysql-metadata-storage\",\"druid-basic-security\",\"simple-client-sslcontext\",\"druid-testing-tools\",\"druid-lookups-cached-global\",\"druid-histogram\",\"druid-datasketches\",\"druid-hdfs-storage\",\"druid-google-extensions\",\"druid-parquet-extensions\",\"druid-avro-extensions\",\"druid-protobuf-extensions\",\"druid-orc-extensions\",\"druid-kafka-indexing-service\"]\nGOOGLE_APPLICATION_CREDENTIALS=/shared/docker/credentials/creds.json"
            retry(3) {
                try {
                    sh script: """
                        mkdir -p jenkins/gcs
                        cp -f \${GC_KEY} jenkins/gcs/creds.json
                        chmod 764 jenkins/gcs/creds.json
                        gsutil \
                            -o Credentials:gs_service_key_file=\${WORKSPACE}/jenkins/gcs/creds.json \
                            cp \${WORKSPACE}/integration-tests/src/test/resources/data/batch_index/json/wikipedia_index_data*.json \
                            gs://${bucket}/${cloudpath}
                    """,
                       label: "copying gcs creds"
                    sh script: """
                        \${MVN} verify -P integration-tests -pl integration-tests \
                        -Doverride.config.path=\${WORKSPACE}/jenkins/gcs-config \
                        -Dresource.file.dir.path=\${WORKSPACE}/jenkins/gcs \
                        -Dgroups=gcs-deep-storage \
                        ${jvmRuntimeOpt} \
                        -Ddruid.test.config.cloudBucket=${bucket} \
                        -Ddruid.test.config.cloudPath=${cloudpath} \
                        -Ddocker.build.hadoop=true \
                        -Dstart.hadoop.docker=true \
                        -ff \${MAVEN_SKIP} -Djacoco.skip=true
                    """,
                       label: "gcs-deep-storage with ${jvmRuntimeOpt}"
                } finally {
                    dockerCleanup()
                    sh script: "gsutil -o Credentials:gs_service_key_file=\${WORKSPACE}/jenkins/gcs/creds.json rm -r gs://${bucket}/${cloudpath}"
                }
            }
        }
    }
}

def hdfsDeepStorageTests(jvmRuntimeOpt) {
    mavenCacheRestore()
    prepareIfconfig()
    getInstanceId()
    writeFile   file:   "jenkins/hdfs-config",
                text:   "druid_storage_type=hdfs\n" +
                        "druid_storage_storageDirectory=/druid/segments\n" +
                        "druid_extensions_loadList=[\"mysql-metadata-storage\",\"druid-basic-security\",\"simple-client-sslcontext\",\"druid-testing-tools\",\"druid-lookups-cached-global\",\"druid-histogram\",\"druid-datasketches\",\"druid-hdfs-storage\",\"druid-parquet-extensions\",\"druid-avro-extensions\",\"druid-protobuf-extensions\",\"druid-orc-extensions\",\"druid-kafka-indexing-service\"]\n" +
                        "druid_indexer_logs_type=hdfs\n" +
                        "druid_indexer_logs_directory=/druid/indexing-logs"
    script {
        retry(2) {
            try {
                sh script: """
                    \${MVN} verify -P integration-tests -pl integration-tests \
                    -Doverride.config.path=\${WORKSPACE}/jenkins/hdfs-config \
                    -Dgroups=hdfs-deep-storage \
                    -Ddocker.build.hadoop=true \
                    -Dstart.hadoop.docker=true \
                    ${jvmRuntimeOpt} \
                    -Ddruid.test.config.extraDatasourceNameSuffix="" \
                    -Dit.test=ITHdfsToHdfsParallelIndexTest \
                    -ff \${MAVEN_SKIP} -Djacoco.skip=true
                """,
                   label: "hdfs-deep-storage with ${jvmRuntimeOpt}"
            } finally {
                dockerCleanup()
            }
        }
    }
}

def coreIntegrationTests() {
    mavenCacheRestore()
    prepareIfconfig()
    getInstanceId()
    script {
        retry(3) {
            try {
                sh script: '''
                    ${MVN} verify -pl integration-tests -P integration-tests \
                    ${TESTNG_GROUPS} ${JVM_RUNTIME} -Dit.indexer=${USE_INDEXER} \
                    ${MAVEN_SKIP}
                ''',
                   label: 'core integration tests'
            } finally {
                dockerCleanup()
            }
        }
    }
}

def coreIntegrationTestsWithPrepopulatedData() {
    mavenCacheRestore()
    prepareIfconfig()
    getInstanceId()
    script {
        retry(3) {
            try {
                sh script: '''
                    ${MVN} verify -pl integration-tests -P integration-tests \
                    ${TESTNG_GROUPS} ${JVM_RUNTIME} -Dit.indexer=${USE_INDEXER} \
                    -Doverride.config.path=../../integration-tests/docker/environment-configs/test-groups/prepopulated-data \
                    ${MAVEN_SKIP}
                ''',
                   label: 'core integration tests'
            } finally {
                dockerCleanup()
            }
        }
    }
}

def coreIntegrationTestsWithShuffleDeepStorage() {
    mavenCacheRestore()
    prepareIfconfig()
    getInstanceId()
    script {
        retry(3) {
            try {
                sh script: '''
                    ${MVN} verify -pl integration-tests -P integration-tests \
                    ${TESTNG_GROUPS} ${JVM_RUNTIME} -Dit.indexer=${USE_INDEXER} \
                    -Doverride.config.path=../../integration-tests/docker/environment-configs/test-groups/shuffle-deep-store \
                    ${MAVEN_SKIP}
                ''',
                   label: 'core integration tests'
            } finally {
                dockerCleanup()
            }
        }
    }
}

def runUnitTest() {
    mavenCacheRestore()
    getInstanceId()
    script {
        try {
            sh script: '''#!/bin/bash
                unset _JAVA_OPTIONS
                # Set MAVEN_OPTS for Surefire launcher. Skip remoteresources to avoid intermittent connection timeouts when
                # resolving the SIGAR dependency.
                export BUILD_STATUS=0
                MAVEN_OPTS='-Xmx2048m' ${MVN} test -pl ${MAVEN_PROJECTS:-processing} \
                    ${MAVEN_SKIP} -Dremoteresources.skip=true -Ddruid.generic.useDefaultValueForNull=${DRUID_USE_DEFAULT_VALUE_FOR_NULL:-true} \
                    || export BUILD_STATUS=1

                ${MVN} -pl ${MAVEN_PROJECTS} jacoco:report
                exit $BUILD_STATUS
            ''',
               label: "processing module test"
        } finally {
            dockerCleanup()
        }
    }
}

def getCodeChanges() {
    script {
        def gitCredsId = scm.getUserRemoteConfigs()[0].getCredentialsId()
        withCredentials([usernamePassword(credentialsId: gitCredsId, usernameVariable: 'GIT_CREDS_USR', passwordVariable: 'GIT_CREDS_PSW')]) {
            sh script: '''#!/bin/bash -eux
                                files=$(curl -u  ${GIT_CREDS_USR}:${GIT_CREDS_PSW} \
                                https://api.github.com/repos/implydata/druid/pulls/${CHANGE_ID}/files \
                                | jq -r '.[] | .filename' |  tr '\\n' ',' | sed 's/.$//'  )
                                any_docs=$(python3 check_test_suite_jenkins.py docs $files|tail -1)
                                any_console=$(python3 check_test_suite_jenkins.py 'web console' $files|tail -1)
                                any_java=$(python3 check_test_suite_jenkins.py any_java $files|tail -1)
                                echo ${any_java} > any_java.info
                                echo ${any_docs} > any_docs.info
                                echo ${any_console} > any_console.info
                            '''
        }
    }
    script {
        env.JAVA_CODE_CHANGES = sh(script: 'head -n 1 any_java.info', returnStdout: true).trim()
    }
    script {
        env.DOC_CODE_CHANGES = sh(script: 'head -n 1 any_docs.info', returnStdout: true).trim()
    }
    script {
        env.CONSOLE_CODE_CHANGES = sh(script: 'head -n 1 any_console.info', returnStdout: true).trim()
    }
    sh 'printenv | sort'
}

@NonCPS
def cancelPreviousBuilds() {
    println("Checking to see if any previous builds need to be aborted.")
    def jobName = env.JOB_NAME
    def buildNumber = env.BUILD_NUMBER.toInteger()
    /* Get job name */
    def currentJob = Jenkins.instance.getItemByFullName(jobName)
    /* Iterating over the builds for specific job */
    for (def build : currentJob.builds) {
        def exec = build.getExecutor()
        /* If there is a build that is currently running and it's not current build */
        if (build.isBuilding() && build.number.toInteger() != buildNumber && exec != null) {
            println("Initiating interrupt of previous build #${build.number}")
            /* Then stop it */
            exec.interrupt(
                    Result.ABORTED,
                    new CauseOfInterruption.UserInterruption("Aborted by #${currentBuild.number}")
            )
            println("Aborted previously running build #${build.number}")
        }
    }
}

pipeline {
    options {
        timeout(time: 4, unit: 'HOURS')
        buildDiscarder(logRotator(artifactDaysToKeepStr: '15', artifactNumToKeepStr: '10', daysToKeepStr: '30', numToKeepStr: '20'))
    }

    parameters {
        booleanParam(name: 'SKIP_ALL_JENKINS_TESTS', defaultValue: false, description: 'Skip all jenkins tests defined in the jenkinsfile')
        booleanParam(name: 'SKIP_JENKINS_INTEGRATION_TESTS', defaultValue: false, description: 'Skip integration tests defined in the jenkinsfile')
        booleanParam(name: 'SKIP_JENKINS_UNIT_TESTS_AND_CHECKS', defaultValue: false, description: 'Skip unit test and checks defined in the jenkinsfile')
        booleanParam(name: 'PUBLISH_ON_ANY_BRANCH', defaultValue: false, description: 'Build and publish to artifactory regardless branch name')
    }

    agent none

    environment {
        MVN = "mvn -B"
        MAVEN_SKIP = "-Pskip-static-checks -Ddruid.console.skip=true -Dmaven.javadoc.skip=true"
        MAVEN_SKIP_TESTS = "-Pskip-tests"
        DOCKER_IP = "127.0.0.1"
        APACHE_ARCHIVE_MIRROR_HOST = "https://repo.cnc.imply.io/artifactory/archive-apache-org-remote"
        COMPOSE_HTTP_TIMEOUT = "600"

        ACTIVE_DEV_BRANCH_REGEX = '^monthly$'
        RELEASE_BRANCH_PREFIX_REGEX = '^release\\/'
        RELEASE_BRANCH_SUFFIX_REGEX = '[^/]+$'

        IMAGE_JDK8 = "docker/druid-ci-jdk8:1647252999"
        IMAGE_JDK11 = "docker/druid-ci-jdk11:1620827975"
        IMAGE_JDK15 = "docker/druid-ci-jdk15:1625878101"
        DOCKER_TAG = "${BUILD_TAG}".replaceAll(~/[^A-Za-z0-9_-]/,'_')
        RT_REGISTRY_URL = "https://repo.cnc.imply.io/artifactory"
        RT_REGISTRY_CREDS = "repo.qa.imply.io"
        RT_SERVER_ID = "repo-qa-imply-io"
        RT_DOCKER_REPOSITORY_PREFIX = "repo.cnc.imply.io"
        DOCKER_REGISTRY_MIRROR = "https://registry-mirror.cnc.imply.io:443"
        DOCKER_AGENT_LABEL = "ubuntu-sysbox-1621268334"
        EXPECTED_SHA1_RUN_DRUID = "164e72426530da8062cd900e6af4e122a777c57d"
        EXPECTED_SHA1_VERIFY_JAVA = "2adffa7d6baeae93c48038816311e691e3b01932"
        EXPECTED_SHA1_RUN_ZK = "ee4c4f10bb721a69738d49c4835d81456992e295"

    }

    stages {
        stage('Cancel old builds, check labels') {
            steps {
                script {
                    // Do not cancel previous monthly builds
                    if (env.BRANCH_NAME != 'monthly') {
                        cancelPreviousBuilds()
                    }
                    if (env.CHANGE_ID && pullRequest.labels.contains("Don't Build")) {
                        currentBuild.result = 'ABORTED'
                        error("Tagged Don't Build")
                    }
                    // Set initial value of JAVA_CODE_CHANGES here because value set in env block cannot be changed
                    env.JAVA_CODE_CHANGES = "True"
                    env.DOC_CODE_CHANGES  =  "True"
                    env.CONSOLE_CODE_CHANGES = "True"
                }
            }
        }

        stage('Maven install') {
            when {
                expression { !params.SKIP_ALL_JENKINS_TESTS }
                beforeAgent true
            }
            environment {
                DOCKER_AGENT_ARGS = "-u root:root --runtime=sysbox-runc -e RUN_DOCKER=1"
            }
            parallel {
                stage('(openjdk8) maven install') {
                    agent {docker {image "${IMAGE_JDK8}"; args "${DOCKER_AGENT_ARGS}"; label "${DOCKER_AGENT_LABEL}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"}}
                    environment { CURRENT_DOCKER_IMAGE="${IMAGE_JDK8}" }
                    steps {
                        mavenInstall()
                        mavenDockerBackup()
                    }
                    post {
                        cleanup {
                            resetWs()
                            dockerCleanup()
                        }
                    }
                }
                stage('(openjdk11) maven install') {
                    agent {docker {image "${IMAGE_JDK11}"; args "${DOCKER_AGENT_ARGS}"; label "${DOCKER_AGENT_LABEL}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"}}
                    environment { CURRENT_DOCKER_IMAGE="${IMAGE_JDK11}" }
                    steps {
                        mavenInstall()
                        mavenDockerBackup()

                    }
                    post {
                        cleanup {
                            resetWs()
                            dockerCleanup()
                        }
                    }
                }
                stage('Verify code changes in PR') {
                    when {
                        beforeAgent true
                        changeRequest()
                    }
                    agent {docker {image "${IMAGE_JDK8}"; args "${DOCKER_AGENT_ARGS}"; label "${DOCKER_AGENT_LABEL}-multi-exec"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"}}
                    environment { CURRENT_DOCKER_IMAGE="${IMAGE_JDK8}" }
                    steps { getCodeChanges() }
                    post {
                        cleanup {
                            resetWs()
                            dockerCleanup()
                        }
                    }
                }
            }
        }
        stage('set build version') {
            agent {
                docker {
                    image 'docker/buildabear:20200923'
                    args '-u root:root'
                    label "${DOCKER_AGENT_LABEL}"
                    registryUrl "${RT_REGISTRY_URL}"
                    registryCredentialsId "${RT_REGISTRY_CREDS}"
                }
            }
            steps {
                script {
                    setupMavenSettings()
                    env.BUILD_VERSION = sh(
                            script: '''#!/bin/bash -eux
                            echo -e '#!/bin/bash\\nPATH=/opt/maven/apache-maven-3.5.4/bin:$PATH exec mvn -B $@' > /usr/bin/mvn
                            chmod u+x /usr/bin/mvn


                            COMMIT_SHA=$(git rev-parse HEAD)
                            if [[ $(git branch origin/${BRANCH_NAME} -r --contains $COMMIT_SHA) ]]; then
                                UPSTREAM_COMMIT_SHA=$COMMIT_SHA
                            else
                                COMMIT_SHA=$(git rev-parse HEAD^)
                                if [[ $(git branch origin/${BRANCH_NAME} -r --contains $COMMIT_SHA) ]]; then
                                    UPSTREAM_COMMIT_SHA=$COMMIT_SHA
                                else
                                    echo "head branch commit SHA is not found"
                                    exit 1
                                fi
                            fi

                            cd $WORKSPACE

                            INIT_DRUID_VERSION=$(mvn org.apache.maven.plugins:maven-help-plugin:3.2.0:evaluate -Dexpression=project.version -q -DforceStdout)
                            DRUID_VERSION=${INIT_DRUID_VERSION%%-SNAPSHOT}
                            mvn versions:set -DnewVersion=$DRUID_VERSION  -DgenerateBackupPoms=false
                            echo "${DRUID_VERSION}-${UPSTREAM_COMMIT_SHA:0:8}"''',
                            returnStdout: true).tokenize().last().trim()
                    echo "${BUILD_VERSION}"
                }
            }
        }

        stage("Build and publish pre test") {
            when {
                anyOf {
                    expression { (env.CHANGE_BRANCH ?: env.BRANCH_NAME) ==~ env.ACTIVE_DEV_BRANCH_REGEX }
                    expression { (env.CHANGE_BRANCH ?: env.BRANCH_NAME) ==~ (env.RELEASE_BRANCH_PREFIX_REGEX + env.RELEASE_BRANCH_SUFFIX_REGEX) }
                    expression { params.PUBLISH_ON_ANY_BRANCH }
                }
                beforeAgent true
            }
            matrix {
                axes {
                    axis {
                        name 'BUILD_PROFILE'
                        values 'dist', 'imply-saas', 'imply-experimental'
                    }
                }
                stages {
                    stage('profile build and upload') {
                        environment {
                            GIT_ASKPASS = "/tmp/askpass.sh"
                            GITHUB_NETRC = "/tmp/github-netrc"
                            STAGING_BASE_DIR= "/tmp/druid-build/stage"
                            TMP_DIR = "/tmp/druid-build/tmp"
                            BUILD_DIR = "/tmp/druid-build"
                            ARTIFACT_NAME = sh(script:"""#!/bin/bash
                                if [ "${BUILD_PROFILE}" == "imply-saas" ]; then
                                    echo "druid-saas"
                                elif [ "${BUILD_PROFILE}" == "imply-experimental" ]; then
                                    echo "druid-experimental"
                                else
                                    echo "druid"
                                fi
                            """, returnStdout: true).trim()
                            ARTIFACTORY_BUILD_NAME = sh(script:"""#!/bin/bash
                                if [ "${BUILD_PROFILE}" == "imply-saas" ]; then
                                    echo "druid.saas"
                                elif [ "${BUILD_PROFILE}" == "imply-experimental" ]; then
                                    echo "druid.experimental"
                                else
                                    echo "druid"
                                fi
                            """, returnStdout: true).trim()
                        }
                        agent {
                            docker {
                                image 'docker/buildabear:20200923'
                                args '-u root:root'
                                label "${DOCKER_AGENT_LABEL}"
                                registryUrl "${RT_REGISTRY_URL}"
                                registryCredentialsId "${RT_REGISTRY_CREDS}"
                            }
                        }
                        stages {
                            stage('prepare to build') {
                                steps {
                                    script {
                                        def gitCredsId = scm.getUserRemoteConfigs()[0].getCredentialsId()
                                        withCredentials([usernamePassword(credentialsId: gitCredsId, usernameVariable: 'GIT_CREDS_USR', passwordVariable: 'GIT_CREDS_PSW')]) {
                                            sh script:'''#!/bin/bash -eux
                                                echo -e '#!/bin/bash\nPATH=/opt/maven/apache-maven-3.5.4/bin:$PATH exec mvn -B $@' > /usr/bin/mvn
                                                chmod u+x /usr/bin/mvn

                                                cat <<EOF > "${GIT_ASKPASS}"
                                                #!/bin/sh
                                                case "\\$1" in
                                                    Username*) echo "${GIT_CREDS_USR}" ;;
                                                    Password*) echo "${GIT_CREDS_PSW}" ;;
                                                esac
                                                EOF

                                                cat <<EOF > "${GITHUB_NETRC}"
                                                machine api.github.com
                                                login ${GIT_CREDS_USR}
                                                password ${GIT_CREDS_PSW}
                                                EOF

                                                chmod u+x "${GIT_ASKPASS}"
                                                chmod 400 "${GITHUB_NETRC}"
                                            '''.replaceAll(/\n\s+/, "\n"),
                                               label: 'prepare for build'
                                        }
                                    }
                                }
                            }
                            stage('build') {
                                steps {
                                    setupMavenSettings()
                                    sh script:'''#!/bin/bash -eux
                                        COMMIT_SHA=$(git rev-parse HEAD)
                                        if [[ $(git branch origin/${BRANCH_NAME} -r --contains $COMMIT_SHA) ]]; then
                                            UPSTREAM_COMMIT_SHA=$COMMIT_SHA
                                        else
                                            COMMIT_SHA=$(git rev-parse HEAD^)
                                            if [[ $(git branch origin/${BRANCH_NAME} -r --contains $COMMIT_SHA) ]]; then
                                                UPSTREAM_COMMIT_SHA=$COMMIT_SHA
                                            else
                                                echo "head branch commit SHA is not found"
                                                exit 1
                                            fi
                                        fi

                                        # Matching the version from pom.xml
                                        DERBYTOOLS_VERSION="10.14.2.0"

                                        # Imply includes additional hadoop libraries (e.g., hadoop-aws)
                                        HADOOP_VERSION="2.8.5"

                                        MARIADB_CONNECTOR_VERSION="2.7.3"

                                        cd $WORKSPACE

                                        # remove snapshot suffix from pom files
                                        INIT_DRUID_VERSION=$(mvn org.apache.maven.plugins:maven-help-plugin:3.2.0:evaluate -Dexpression=project.version -q -DforceStdout)
                                        DRUID_VERSION=${INIT_DRUID_VERSION%%-SNAPSHOT}
                                        mvn versions:set -DnewVersion=$DRUID_VERSION  -DgenerateBackupPoms=false

                                        current_java_version=$(java -version 2>&1 >/dev/null | grep 'version' | awk '{print $3}')
                                        echo "Compiling Druid with current Java version set. Java version=$current_java_version"

                                        mvn clean install \
                                            -Dhadoop.compile.version="$HADOOP_VERSION" \
                                            -Danimal.sniffer.skip=true \
                                            -Dcheckstyle.skip=true \
                                            -Denforcer.skip=true \
                                            -Dforbiddenapis.skip=true \
                                            -Djacoco.skip=true \
                                            -Dmaven.javadoc.skip=true \
                                            -Dpmd.skip=true \
                                            -Dspotbugs.skip=true \
                                            -DskipTests \
                                            -T1C \
                                            -Dtar \
                                            -P${BUILD_PROFILE}

                                        echo "Built Druid, version: $DRUID_VERSION"

                                        # Stage Druid
                                        export STAGING_DIR=${STAGING_BASE_DIR}/${BUILD_PROFILE}
                                        mkdir -p "$STAGING_DIR/dist"
                                        mkdir -p "$TMP_DIR"
                                        tar -C "$TMP_DIR" -xzf "$WORKSPACE"/distribution/target/apache-druid-*-bin.tar.gz
                                        mv "$TMP_DIR"/apache-druid-* "$STAGING_DIR/dist/druid"

                                        # Fetch the MariaDB Client from mariadb.com
                                        MARIADB_CONNECTOR_LOCATION="$STAGING_DIR/dist/druid/extensions/mysql-metadata-storage/mariadb-java-client-${MARIADB_CONNECTOR_VERSION}.jar"
                                        #mkdir -p "$STAGING_DIR/dist/druid/extensions/mysql-metadata-storage"
                                        curl -o "$MARIADB_CONNECTOR_LOCATION" --retry 10 "https://downloads.mariadb.com/Connectors/java/connector-java-${MARIADB_CONNECTOR_VERSION}/mariadb-java-client-${MARIADB_CONNECTOR_VERSION}.jar"

                                        if [ "$(sha1sum "$MARIADB_CONNECTOR_LOCATION" | awk '{print $1}')" != "4a2edc05bd882ad19371d2615c2635dccf8d74f0" ]
                                        then
                                          echo "$MARIADB_CONNECTOR_LOCATION: checksum mismatch" >&2
                                          exit 1
                                        fi

                                        # Add hadoop-aws
                                        (cd "$STAGING_DIR"/dist/druid && java -classpath "lib/*" org.apache.druid.cli.Main tools pull-deps -h "org.apache.hadoop:hadoop-aws:${HADOOP_VERSION}")

                                        # Add derbytools to lib
                                        DERBYTOOLS_LOCATION="$STAGING_DIR/dist/druid/lib/derbytools-$DERBYTOOLS_VERSION.jar"
                                        curl -Lo "$DERBYTOOLS_LOCATION" "https://search.maven.org/remotecontent?filepath=org/apache/derby/derbytools/$DERBYTOOLS_VERSION/derbytools-$DERBYTOOLS_VERSION.jar"

                                        if [ "$(sha1sum "$DERBYTOOLS_LOCATION" | awk '{print $1}')" != "338d5a54b4089c80414fe0ecb3899d521da69b26" ]
                                        then
                                          echo "$DERBYTOOLS_LOCATION: checksum mismatch" >&2
                                          exit 1
                                        fi

                                        # Remove unsupported open-source extensions
                                        for extension in druid-pac4j druid-ranger-security materialized-view-maintenance materialized-view-selection; do
                                            rm -rf "${STAGING_DIR}/dist/druid/extensions/${extension}"
                                        done

                                        # Put druid on a diet
                                        perl - <<'EOT'
                                        use strict;
                                        use File::Basename;

                                        my $dir = "$ENV{STAGING_DIR}/dist/druid";
                                        chdir $dir or die "chdir $dir: $!";

                                        my %jars;
                                        for my $jar (qx!find ./lib -name '*.jar'!, qx!find ./extensions -name '*.jar'!, qx!find ./hadoop-dependencies -name '*.jar'!) {
                                          chomp $jar;
                                          my $jarname = basename($jar);
                                          if (exists $jars{$jarname}) {
                                            my $depth = $jar =~ tr !/!/! - 1;
                                            my $dots = "";
                                            for my $x (1..$depth) {
                                              $dots .= "../";
                                            }
                                            system("ln", "-sf", "${dots}$jars{$jarname}", $jar);
                                          } else {
                                            $jars{$jarname} = $jar;
                                          }
                                        }
                                        EOT

                                        function verify_checksum() {
                                            local file="$1"
                                            local checksum="$2"
                                            if [ "$(sha1sum "$file" | awk '{print $1}')" != "$checksum" ]; then
                                                1>&2 cat << EOF
                                                    $file has changed in the druid repo! Look at the changes and incorporate them in the
                                                    script if needed. Then update the expected sha1 in this script. Also update the imply
                                                    startup scripts located at https://github.com/implydata/imply-release/blob/master/imply-resources/bin/$file
                                                EOF
                                                exit 1
                                            fi
                                        }

                                        verify_checksum "$STAGING_DIR/dist/druid/bin/run-druid" "$EXPECTED_SHA1_RUN_DRUID"
                                        verify_checksum "$STAGING_DIR/dist/druid/bin/verify-java" "$EXPECTED_SHA1_VERIFY_JAVA"
                                        verify_checksum "$STAGING_DIR/dist/druid/bin/run-zk" "$EXPECTED_SHA1_RUN_ZK"

                                        tar -C $STAGING_DIR/dist -czf $WORKSPACE/${ARTIFACT_NAME}-${DRUID_VERSION}-${UPSTREAM_COMMIT_SHA:0:8}.tar.gz druid

                                        echo "${DRUID_VERSION}-${UPSTREAM_COMMIT_SHA:0:8}" > $WORKSPACE/build.version

                                    '''.replaceAll(/\n\s+/, "\n"),
                                       label: 'build druid and verify'
                                } // end of steps
                            } // end of stage('build')
                            stage('prepare upload') {
                                steps {
                                    setupMavenSettings()
                                    sh script:'''#!/bin/bash -eux
                                        COMMIT_SHA=$(git rev-parse HEAD)
                                        if [[ $(git branch origin/${BRANCH_NAME} -r --contains $COMMIT_SHA) ]]; then
                                            UPSTREAM_COMMIT_SHA=$COMMIT_SHA
                                        else
                                            COMMIT_SHA=$(git rev-parse HEAD^)
                                            if [[ $(git branch origin/${BRANCH_NAME} -r --contains $COMMIT_SHA) ]]; then
                                                UPSTREAM_COMMIT_SHA=$COMMIT_SHA
                                            else
                                                echo "head branch commit SHA is not found"
                                                exit 1
                                            fi
                                        fi

                                        cd $WORKSPACE

                                        # remove snapshot suffix from pom files
                                        INIT_DRUID_VERSION=$(mvn org.apache.maven.plugins:maven-help-plugin:3.2.0:evaluate -Dexpression=project.version -q -DforceStdout)
                                        DRUID_VERSION=${INIT_DRUID_VERSION%%-SNAPSHOT}
                                        mvn versions:set -DnewVersion=$DRUID_VERSION  -DgenerateBackupPoms=false

                                        # Stage Druid
                                        export STAGING_DIR=${STAGING_BASE_DIR}/${BUILD_PROFILE}


                                        echo "${DRUID_VERSION}-${UPSTREAM_COMMIT_SHA:0:8}" > $WORKSPACE/build.version

                                    '''.replaceAll(/\n\s+/, "\n"),
                                       label: 'build druid and verify'
                                } // end of steps
                            } // end of stage('build')

                            stage('upload') {
                                steps {
                                    script {
                                        def release_version = "None"
                                        def headBranch = env.CHANGE_BRANCH ?: env.BRANCH_NAME
                                        if(headBranch ==~ (env.RELEASE_BRANCH_PREFIX_REGEX + env.RELEASE_BRANCH_SUFFIX_REGEX)) {
                                            release_version = (headBranch =~ env.RELEASE_BRANCH_SUFFIX_REGEX).getAt(0)
                                        } else if(headBranch ==~ env.ACTIVE_DEV_BRANCH_REGEX) {
                                            release_version = sh(
                                                    script: '''#!/bin/bash -e
                                                    curl -s --netrc-file ${GITHUB_NETRC} \
                                                    -H "Accept: application/vnd.github.v3.raw" \
                                                    https://api.github.com/repos/implydata/imply-release/contents/monthly-release.version |  \
                                                    tee /dev/stderr
                                                ''',
                                                    returnStdout: true
                                            ).trim()
                                        }
                                        def artifact_build_version = sh(
                                                script: 'cat build.version',
                                                returnStdout: true
                                        ).trim()
                                        def repo_url = sh(
                                                script: 'git config --get remote.origin.url',
                                                returnStdout: true
                                        ).trim()
                                        rtUpload (
                                                serverId: "${RT_SERVER_ID}",
                                                spec: """{
                                                "files": [
                                                    {
                                                      "pattern": "${ARTIFACT_NAME}-${artifact_build_version}.tar.gz",
                                                      "target": "tgz-local/${ARTIFACT_NAME}/",
                                                      "props": "release.version=${release_version};BVT=InProgress;build.url=${BUILD_URL};vcs.url=${repo_url};vcs.branch=${headBranch};build.version=${artifact_build_version}"
                                                    }
                                                ]
                                            }""",
                                                buildName: "${ARTIFACTORY_BUILD_NAME}",
                                                buildNumber: "${BUILD_NUMBER}"
                                        )
                                        // this is used to know whether or not to mark as failure. And avoid errors for something that fails before the artifact is uploaded.
                                        env.BUILD_UPLOAD_SUCCESS = true
                                    }
                                }
                            } // end of stage('upload')
                        } // end of stages
                        post {
                            cleanup {
                                resetWs()
                            }
                        }
                    } // end of stage('profile build and upload')
                } // end of stages
            } // end of matrix
        } // end of stage("Build and publish")

        stage('Tests - phase 1') {
            when {
                expression { !params.SKIP_JENKINS_UNIT_TESTS_AND_CHECKS && !params.SKIP_ALL_JENKINS_TESTS }
                beforeAgent true
            }
            environment {
                DOCKER_AGENT_ARGS = "-u root:root"
            }
            parallel {
                stage('animal sniffer checks') {
                    when {
                        expression { !params.SKIP_JENKINS_UNIT_TESTS_AND_CHECKS && !params.SKIP_ALL_JENKINS_TESTS && env.JAVA_CODE_CHANGES == "True" }
                        beforeAgent true
                    }
                    agent {docker {image "${IMAGE_JDK8}-${DOCKER_TAG}";args "${DOCKER_AGENT_ARGS}";registryUrl "${RT_REGISTRY_URL}";registryCredentialsId "${RT_REGISTRY_CREDS}";label "${DOCKER_AGENT_LABEL}-multi-exec"}}
                    steps { mavenCacheRestore(); sh "${MVN} animal-sniffer:check --fail-at-end" }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage('checkstyle') {
                    when {
                        expression { env.JAVA_CODE_CHANGES == "True" }
                        beforeAgent true
                    }
                    agent {docker {image "${IMAGE_JDK8}-${DOCKER_TAG}";args "${DOCKER_AGENT_ARGS}";registryUrl "${RT_REGISTRY_URL}";registryCredentialsId "${RT_REGISTRY_CREDS}";label "${DOCKER_AGENT_LABEL}-multi-exec"}}
                    steps { mavenCacheRestore(); sh "${MVN} checkstyle:checkstyle --fail-at-end" }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage('enforcer checks') {
                    when {
                        expression { env.JAVA_CODE_CHANGES == "True" }
                        beforeAgent true
                    }
                    agent {docker {image "${IMAGE_JDK8}-${DOCKER_TAG}";args "${DOCKER_AGENT_ARGS}";registryUrl "${RT_REGISTRY_URL}";registryCredentialsId "${RT_REGISTRY_CREDS}";label "${DOCKER_AGENT_LABEL}-multi-exec"}}
                    steps { mavenCacheRestore(); sh "${MVN} enforcer:enforce --fail-at-end" }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage('forbidden api checks') {
                    when {
                        expression { env.JAVA_CODE_CHANGES == "True" }
                        beforeAgent true
                    }
                    agent {docker {image "${IMAGE_JDK8}-${DOCKER_TAG}";args "${DOCKER_AGENT_ARGS}";registryUrl "${RT_REGISTRY_URL}";registryCredentialsId "${RT_REGISTRY_CREDS}";label "${DOCKER_AGENT_LABEL}-multi-exec"}}
                    steps { mavenCacheRestore(); sh "${MVN} forbiddenapis:check forbiddenapis:testCheck --fail-at-end" }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage('pmd checks') {
                    when {
                        expression { env.JAVA_CODE_CHANGES == "True" }
                        beforeAgent true
                    }
                    agent {docker {image "${IMAGE_JDK8}-${DOCKER_TAG}";args "${DOCKER_AGENT_ARGS}";registryUrl "${RT_REGISTRY_URL}";registryCredentialsId "${RT_REGISTRY_CREDS}";label "${DOCKER_AGENT_LABEL}-multi-exec"}}
                    steps { mavenCacheRestore(); sh "${MVN} pmd:check --fail-at-end" }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage('spotbugs checks') {
                    when {
                        expression { env.JAVA_CODE_CHANGES == "True" }
                        beforeAgent true
                    }
                    agent {docker {image "${IMAGE_JDK8}-${DOCKER_TAG}";args "${DOCKER_AGENT_ARGS}";registryUrl "${RT_REGISTRY_URL}";registryCredentialsId "${RT_REGISTRY_CREDS}";label "${DOCKER_AGENT_LABEL}-multi-exec"}}
                    steps { mavenCacheRestore(); sh "${MVN} spotbugs:check --fail-at-end -pl '!benchmarks'" }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage('license checks') {
                    agent {
                        docker {
                            image "${IMAGE_JDK8}-${DOCKER_TAG}"
                            args "${DOCKER_AGENT_ARGS}"
                            registryUrl "${RT_REGISTRY_URL}"
                            registryCredentialsId "${RT_REGISTRY_CREDS}"
                            label "${DOCKER_AGENT_LABEL}"
                        }
                    }
                    steps {
                        mavenCacheRestore()
                        sh """
                            ${MVN} apache-rat:check -Prat --fail-at-end \
                                -Dorg.slf4j.simpleLogger.log.org.apache.maven.cli.transfer.Slf4jMavenTransferListener=warn \
                                -Drat.consoleOutput=true
                            # Generate dependency reports and checks they are valid. When running on Travis CI, 2 cores are available
                            # (https://docs.travis-ci.com/user/reference/overview/#virtualisation-environment-vs-operating-system).
                            mkdir -p target
                            distribution/bin/generate-license-dependency-reports.py . target --clean-maven-artifact-transfer --parallel 2
                            distribution/bin/check-licenses.py licenses.yaml target/license-reports
                        """
                    }
                    post {
                        always { buildArtifacts(env.STAGE_NAME) }
                        cleanup { resetWs() }
                    }
                }
                stage('(openjdk11) strict compilation') {
                    when {
                        expression { env.JAVA_CODE_CHANGES == "True" }
                        beforeAgent true
                    }
                    agent {
                        docker {
                            image "${IMAGE_JDK11}"
                            args "${DOCKER_AGENT_ARGS}"
                            registryUrl "${RT_REGISTRY_URL}"
                            registryCredentialsId "${RT_REGISTRY_CREDS}"
                            label "${DOCKER_AGENT_LABEL}"
                        }
                    }
                    environment {
                        MAVEN_OPTS = "-Xms4g -Xmx8g -XX:MaxDirectMemorySize=2048m"
                    }
                    steps {
                        setupMavenSettings()
                        sh """
                            ${MVN} clean -DstrictCompile compile test-compile --fail-at-end \
                                ${MAVEN_SKIP} ${MAVEN_SKIP_TESTS}
                        """
                    }
                    post {
                        always { buildArtifacts(env.STAGE_NAME) }
                        cleanup { resetWs() }
                    }
                }

                stage('analyze dependencies') {
                    when {
                        expression { env.JAVA_CODE_CHANGES == "True" }
                        beforeAgent true
                    }
                    agent {
                        docker {
                            image "${IMAGE_JDK8}-${DOCKER_TAG}"
                            args "${DOCKER_AGENT_ARGS}"
                            registryUrl "${RT_REGISTRY_URL}"
                            registryCredentialsId "${RT_REGISTRY_CREDS}"
                            label "${DOCKER_AGENT_LABEL}"
                        }
                    }
                    environment {
                        MAVEN_OPTS = "-Xms4g -Xmx8g -XX:MaxDirectMemorySize=2048m"
                    }
                    steps {
                        mavenCacheRestore()
                        sh """
                            MAVEN_OPTS='-Xmx3000m' ${MVN} ${MAVEN_SKIP} dependency:analyze -DoutputXML=true -DignoreNonCompile=true -DfailOnWarning=true || { echo "

                            The dependency analysis has found a dependency that is either:

                            1) Used and undeclared: These are available as a transitive dependency but should be explicitly
                            added to the POM to ensure the dependency version. The XML to add the dependencies to the POM is
                            shown above.

                            2) Unused and declared: These are not needed and removing them from the POM will speed up the build
                            and reduce the artifact size. The dependencies to remove are shown above.

                            If there are false positive dependency analysis warnings, they can be suppressed:
                            https://maven.apache.org/plugins/maven-dependency-plugin/analyze-mojo.html#usedDependencies
                            https://maven.apache.org/plugins/maven-dependency-plugin/examples/exclude-dependencies-from-dependency-analysis.html

                            For more information, refer to:
                            https://maven.apache.org/plugins/maven-dependency-plugin/analyze-mojo.html

                            " && false; }
                        """
                    }
                    post {
                        always { buildArtifacts(env.STAGE_NAME) }
                        cleanup { resetWs() }
                    }
                }

                stage('analyze hadoop 3 dependencies"') {
                    when {
                        expression { env.JAVA_CODE_CHANGES == "True" }
                        beforeAgent true
                    }
                    agent {
                        docker {
                            image "${IMAGE_JDK8}-${DOCKER_TAG}"
                            args "${DOCKER_AGENT_ARGS}"
                            registryUrl "${RT_REGISTRY_URL}"
                            registryCredentialsId "${RT_REGISTRY_CREDS}"
                            label "${DOCKER_AGENT_LABEL}"
                        }
                    }
                    environment {
                        MAVEN_OPTS = "-Xms4g -Xmx8g -XX:MaxDirectMemorySize=2048m"
                    }
                    steps {
                        mavenCacheRestore()
                        sh """
                            MAVEN_OPTS='-Xmx3000m' ${MVN} ${MAVEN_SKIP} dependency:analyze -DoutputXML=true -DignoreNonCompile=true -DfailOnWarning=true -Phadoop3 || { echo "

                            The dependency analysis has found a dependency that is either:

                            1) Used and undeclared: These are available as a transitive dependency but should be explicitly
                            added to the POM to ensure the dependency version. The XML to add the dependencies to the POM is
                            shown above.

                            2) Unused and declared: These are not needed and removing them from the POM will speed up the build
                            and reduce the artifact size. The dependencies to remove are shown above.

                            If there are false positive dependency analysis warnings, they can be suppressed:
                            https://maven.apache.org/plugins/maven-dependency-plugin/analyze-mojo.html#usedDependencies
                            https://maven.apache.org/plugins/maven-dependency-plugin/examples/exclude-dependencies-from-dependency-analysis.html

                            For more information, refer to:
                            https://maven.apache.org/plugins/maven-dependency-plugin/analyze-mojo.html

                            " && false; }
                        """
                    }
                    post {
                        always { buildArtifacts(env.STAGE_NAME) }
                        cleanup { resetWs() }
                    }
                }

                stage('intellij inspections') {
                    when {
                        expression { env.JAVA_CODE_CHANGES == "True" }
                        beforeAgent true
                    }
                    agent {
                        docker {
                            image "${IMAGE_JDK8}-${DOCKER_TAG}"
                            args "-u jenkins --runtime=sysbox-runc -e RUN_DOCKER=1"
                            registryUrl "${RT_REGISTRY_URL}"
                            registryCredentialsId "${RT_REGISTRY_CREDS}"
                            label "${DOCKER_AGENT_LABEL}-multi-exec"
                        }
                    }
                    steps {
                        mavenCacheRestore()
                        sh script:'''
                            mkdir -p inspection-results
                            chmod -R 777 inspection-results
                        ''',
                           label: 'prepare output directory'

                        sh script:'''
                            docker run --rm \
                            -v ${WORKSPACE}:/project \
                            -v ${HOME}/.m2/repository:/home/inspect/.m2/repository \
                            -v ${WORKSPACE}/inspection-results:/home/inspect/inspection-results \
                            repo.cnc.imply.io/docker/ccaominh/intellij-inspect:1.0.0 \
                            /project/pom.xml \
                            /project/.idea/inspectionProfiles/Druid.xml \
                            --levels ERROR \
                            --scope JavaInspectionsScope
                        ''',
                           label: 'intellij inspections'
                    }
                    post {
                        always { buildArtifacts(env.STAGE_NAME) }
                        cleanup { resetWs() }
                    }
                }

                stage('(openjdk8) packaging check') {
                    agent {
                        docker {
                            image "${IMAGE_JDK8}-${DOCKER_TAG}"
                            args "${DOCKER_AGENT_ARGS}"
                            registryUrl "${RT_REGISTRY_URL}"
                            registryCredentialsId "${RT_REGISTRY_CREDS}"
                            label "${DOCKER_AGENT_LABEL}-multi-exec"
                        }
                    }
                    environment {
                        MAVEN_OPTS = "-Xms4g -Xmx8g -XX:MaxDirectMemorySize=2048m"
                    }
                    steps {
                        setupMavenSettings()
                        sh script:'''
                            MAVEN_OPTS='-Xmx3000m' ${MVN} clean install -Prat -Pdist -Pbundle-contrib-exts --fail-at-end \
                                -pl '!benchmarks' ${MAVEN_SKIP} ${MAVEN_SKIP_TESTS} -Ddruid.console.skip=false -T1C
                        '''
                    }
                    post {
                        always { buildArtifacts(env.STAGE_NAME) }
                        cleanup { resetWs() }
                    }
                }

                stage('(openjdk11) packaging check') {
                    agent {
                        docker {
                            image "${IMAGE_JDK11}-${DOCKER_TAG}"
                            args "${DOCKER_AGENT_ARGS}"
                            registryUrl "${RT_REGISTRY_URL}"
                            registryCredentialsId "${RT_REGISTRY_CREDS}"
                            label "${DOCKER_AGENT_LABEL}-multi-exec"
                        }
                    }
                    environment {
                        MAVEN_OPTS = "-Xms4g -Xmx8g -XX:MaxDirectMemorySize=2048m"
                    }
                    steps {
                        setupMavenSettings()
                        sh script: '''
                            MAVEN_OPTS='-Xmx3000m' ${MVN} clean install -Prat -Pdist -Pbundle-contrib-exts --fail-at-end \
                                -pl '!benchmarks' ${MAVEN_SKIP} ${MAVEN_SKIP_TESTS} -Ddruid.console.skip=false -T1C
                        '''
                    }
                    post {
                        always { buildArtifacts(env.STAGE_NAME) }
                        cleanup { resetWs() }
                    }
                }

                stage('web console') {
                    when {
                        expression { env.CONSOLE_CODE_CHANGES == "True" }
                        beforeAgent true
                    }
                    agent {
                        docker {
                            image "${IMAGE_JDK8}-${DOCKER_TAG}"
                            args "${DOCKER_AGENT_ARGS}"
                            registryUrl "${RT_REGISTRY_URL}"
                            registryCredentialsId "${RT_REGISTRY_CREDS}"
                            label "${DOCKER_AGENT_LABEL}-multi-exec"
                        }
                    }
                    steps {
                        setupMavenSettings()
                        sh script:'''
                            ${MVN} test -pl 'web-console'
                        '''
                    }
                    post {
                        always { buildArtifacts(env.STAGE_NAME) }
                        cleanup { resetWs() }
                        success {
                            sh script:'''
                                cd web-console
                                { for i in 1 2 3; do npm run codecov && break || sleep 15; done }
                            '''
                        }
                    }
                }

                stage('web-console end-to-end test') {
                    when {
                        expression { env.CONSOLE_CODE_CHANGES == "True" }
                        beforeAgent true
                    }
                    agent {
                        docker {
                            image "${IMAGE_JDK8}-${DOCKER_TAG}"
                            args "${DOCKER_AGENT_ARGS}"
                            registryUrl "${RT_REGISTRY_URL}"
                            registryCredentialsId "${RT_REGISTRY_CREDS}"
                            label "${DOCKER_AGENT_LABEL}"
                        }
                    }
                    steps {
                        setupMavenSettings()
                        sh script: '''
                                web-console/script/druid build
                                echo 'Starting nvm install...'
                                curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.34.0/install.sh | bash
                                [ -s "/root/.nvm/nvm.sh" ] && . "/root/.nvm/nvm.sh"  # This loads nvm
                                nvm install 14.19.0
                                web-console/script/druid start
                                cd web-console && npm run test-e2e
                            '''
                    }
                    post {
                        always { buildArtifacts(env.STAGE_NAME) }
                        cleanup { resetWs() }
                    }
                }

                stage('docs') {
                    // Run this stage when it is not a PR or in case of PR only run when there is a change in
                    // docs and website directory
                    when {
                        expression { env.DOC_CODE_CHANGES == "True" }
                        beforeAgent true
                    }
                    agent {
                        docker {
                            image "${IMAGE_JDK8}"
                            args "${DOCKER_AGENT_ARGS}"
                            registryUrl "${RT_REGISTRY_URL}"
                            registryCredentialsId "${RT_REGISTRY_CREDS}"
                            label "${DOCKER_AGENT_LABEL}-multi-exec"
                        }
                    }
                    steps {
                        sh script:'''
                            (cd website && npm install)
                            (cd website && npm run lint && npm run spellcheck) || { echo "

                            If there are spell check errors:

                            1) Suppressing False Positives: Edit website/.spelling to add suppressions. Instructions
                            are at the top of the file and explain how to suppress false positives either globally or
                            within a particular file.

                            2) Running Spell Check Locally: cd website && npm install && npm run spellcheck

                            For more information, refer to: https://www.npmjs.com/package/markdown-spellcheck

                            " && false; }
                        '''
                    }
                    post {
                        always { buildArtifacts(env.STAGE_NAME) }
                        cleanup { resetWs() }
                    }
                }

                stage('(openjdk8) processing module test') {
                    when {
                        expression { env.JAVA_CODE_CHANGES == "True" }
                        beforeAgent true
                    }
                    agent {docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "-u jenkins --runtime=sysbox-runc -e RUN_DOCKER=1"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" }}
                    environment {
                        MAVEN_PROJECTS="processing"
                        DRUID_USE_DEFAULT_VALUE_FOR_NULL="true"
                    }
                    steps { runUnitTest() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage('(openjdk8) processing module test (SQL Compatibility)') {
                    when {
                        expression { env.JAVA_CODE_CHANGES == "True" }
                        beforeAgent true
                    }
                    agent {docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "-u jenkins --runtime=sysbox-runc -e RUN_DOCKER=1"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" }}
                    environment {
                        MAVEN_PROJECTS="processing"
                        DRUID_USE_DEFAULT_VALUE_FOR_NULL="false"
                    }
                    steps { runUnitTest() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage('(openjdk8) indexing modules test') {
                    when {
                        expression { env.JAVA_CODE_CHANGES == "True" }
                        beforeAgent true
                    }
                    agent {docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "-u jenkins --runtime=sysbox-runc -e RUN_DOCKER=1"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" }}
                    environment {
                        MAVEN_PROJECTS="indexing-hadoop,indexing-service,extensions-core/kafka-indexing-service,extensions-core/kinesis-indexing-service"
                        DRUID_USE_DEFAULT_VALUE_FOR_NULL="true"
                    }
                    steps { runUnitTest() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage('(openjdk8) indexing modules test (SQL Compatibility)') {
                    when {
                        expression { env.JAVA_CODE_CHANGES == "True" }
                        beforeAgent true
                    }
                    agent {docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "-u jenkins --runtime=sysbox-runc -e RUN_DOCKER=1"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" }}
                    environment {
                        MAVEN_PROJECTS="indexing-hadoop,indexing-service,extensions-core/kafka-indexing-service,extensions-core/kinesis-indexing-service"
                        DRUID_USE_DEFAULT_VALUE_FOR_NULL="false"
                    }
                    steps { runUnitTest() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage('(openjdk8) server module test') {
                    when {
                        expression { env.JAVA_CODE_CHANGES == "True" }
                        beforeAgent true
                    }
                    agent {docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "-u jenkins --runtime=sysbox-runc -e RUN_DOCKER=1"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" }}
                    environment {
                        MAVEN_PROJECTS="server"
                        DRUID_USE_DEFAULT_VALUE_FOR_NULL="true"
                    }
                    steps { runUnitTest() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage('(openjdk8) server module test (SQL Compatibility)') {
                    when {
                        expression { env.JAVA_CODE_CHANGES == "True" }
                        beforeAgent true
                    }
                    agent {docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "-u jenkins --runtime=sysbox-runc -e RUN_DOCKER=1"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" }}
                    environment {
                        MAVEN_PROJECTS="server"
                        DRUID_USE_DEFAULT_VALUE_FOR_NULL="false"
                    }
                    steps { runUnitTest() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage('(openjdk8) other modules test') {
                    when {
                        expression { env.JAVA_CODE_CHANGES == "True" }
                        beforeAgent true
                    }
                    agent {docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "-u jenkins --runtime=sysbox-runc -e RUN_DOCKER=1"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" }}
                    environment {
                        MAVEN_PROJECTS="!processing,!indexing-hadoop,!indexing-service,!extensions-core/kafka-indexing-service,!extensions-core/kinesis-indexing-service,!server,!web-console,!integration-tests,!processing,!indexing-hadoop,!indexing-service,!extensions-core/kafka-indexing-service,!extensions-core/kinesis-indexing-service,!server,!web-console,!integration-tests"
                        DRUID_USE_DEFAULT_VALUE_FOR_NULL="true"
                    }
                    steps { runUnitTest() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage('(openjdk8) other modules test (SQL Compatibility)') {
                    when {
                        expression { env.JAVA_CODE_CHANGES == "True" }
                        beforeAgent true
                    }
                    agent {docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "-u jenkins --runtime=sysbox-runc -e RUN_DOCKER=1"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" }}
                    environment {
                        MAVEN_PROJECTS="!processing,!indexing-hadoop,!indexing-service,!extensions-core/kafka-indexing-service,!extensions-core/kinesis-indexing-service,!server,!web-console,!integration-tests,!processing,!indexing-hadoop,!indexing-service,!extensions-core/kafka-indexing-service,!extensions-core/kinesis-indexing-service,!server,!web-console,!integration-tests"
                        DRUID_USE_DEFAULT_VALUE_FOR_NULL="false"
                    }
                    steps { runUnitTest() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }
            }
        }

        stage('Tests - phase 2') {
            when {
                expression { !params.SKIP_JENKINS_INTEGRATION_TESTS && !params.SKIP_ALL_JENKINS_TESTS && env.JAVA_CODE_CHANGES == "True" }
                beforeAgent true
            }
            environment {
                DOCKER_AGENT_ARGS = "-u root:root --runtime=sysbox-runc -e RUN_DOCKER=1"
            }
            parallel {
                stage('security vulnerabilities') {
                    agent {
                        docker {
                            image "${IMAGE_JDK8}-${DOCKER_TAG}"
                            args "${DOCKER_AGENT_ARGS}"
                            label "${DOCKER_AGENT_LABEL}-multi-exec"
                            registryUrl "${RT_REGISTRY_URL}"
                            registryCredentialsId "${RT_REGISTRY_CREDS}"
                        }
                    }
                    steps {
                        mavenCacheRestore()
                        sh script: '''#!/bin/bash
                            set -o pipefail

                            dependency_check() {
                                rm -f /tmp/component-reports-failed
                                touch /tmp/component-reports-failed
                                ${MVN} dependency-check:aggregate -pl '!integration-tests,!integration-tests-imply,!api-contract' 2>&1 | \
                                tee >(grep -F 'Failed to request component-reports' >> /tmp/component-reports-failed)
                            }

                            DEPENDENCY_CHECK_STATUS=0
                            ALL_ATTEMPTS_FAILED=0

                            for i in $(seq 1 10); do
                                if dependency_check; then
                                    echo "Dependency check succeeded"
                                    break
                                elif [[ $(cat /tmp/component-reports-failed) ]]; then
                                    if [[ "${i}" = "10" ]]; then
                                        echo "All attempts are failed"
                                        ALL_ATTEMPTS_FAILED=1
                                    else
                                        echo "Sleeping 30 seconds before next attempt"
                                        sleep 30
                                    fi
                                else
                                    echo "Dependency check failed not from component-reports issue. Failing"
                                    DEPENDENCY_CHECK_STATUS=1
                                    break
                                fi
                            done

                            [[ "${DEPENDENCY_CHECK_STATUS}" = "0" ]] || { echo "The OWASP dependency check has found security vulnerabilities. Please use a newer version
                            of the dependency that does not have vulnerabilities. If the analysis has false positives,
                            they can be suppressed by adding entries to owasp-dependency-check-suppressions.xml (for more
                            information, see https://jeremylong.github.io/DependencyCheck/general/suppression.html).
                            " && exit 1; }

                            [[ "${ALL_ATTEMPTS_FAILED}" = "0" ]] || false
                        ''',
                           label: 'dependency check'
                    }
                    post { cleanup { resetWs() } }
                }

                stage('(openjdk11) processing module test') {
                    agent { docker { image "${IMAGE_JDK11}-${DOCKER_TAG}"; args "-u jenkins --runtime=sysbox-runc -e RUN_DOCKER=1"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment {
                        MAVEN_PROJECTS = "processing"
                        DRUID_USE_DEFAULT_VALUE_FOR_NULL = "true"
                    }
                    steps { runUnitTest() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage('(openjdk11) processing module test (SQL Compatibility)') {
                    agent { docker { image "${IMAGE_JDK11}-${DOCKER_TAG}"; args "-u jenkins --runtime=sysbox-runc -e RUN_DOCKER=1"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment {
                        MAVEN_PROJECTS = "processing"
                        DRUID_USE_DEFAULT_VALUE_FOR_NULL = "false"
                    }
                    steps { runUnitTest() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage('(openjdk11) indexing modules test') {
                    agent { docker { image "${IMAGE_JDK11}-${DOCKER_TAG}"; args "-u jenkins --runtime=sysbox-runc -e RUN_DOCKER=1"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment {
                        MAVEN_PROJECTS = "indexing-hadoop,indexing-service,extensions-core/kafka-indexing-service,extensions-core/kinesis-indexing-service"
                        DRUID_USE_DEFAULT_VALUE_FOR_NULL = "true"
                    }
                    steps { runUnitTest() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage('(openjdk11) indexing modules test (SQL Compatibility)') {
                    agent { docker { image "${IMAGE_JDK11}-${DOCKER_TAG}"; args "-u jenkins --runtime=sysbox-runc -e RUN_DOCKER=1"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment {
                        MAVEN_PROJECTS = "indexing-hadoop,indexing-service,extensions-core/kafka-indexing-service,extensions-core/kinesis-indexing-service"
                        DRUID_USE_DEFAULT_VALUE_FOR_NULL = "false"
                    }
                    steps { runUnitTest() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage('(openjdk11) server module test') {
                    agent { docker { image "${IMAGE_JDK11}-${DOCKER_TAG}"; args "-u jenkins --runtime=sysbox-runc -e RUN_DOCKER=1"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment {
                        MAVEN_PROJECTS = "server"
                        DRUID_USE_DEFAULT_VALUE_FOR_NULL = "true"
                    }
                    steps { runUnitTest() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage('(openjdk11) server module test (SQL Compatibility)') {
                    agent { docker { image "${IMAGE_JDK11}-${DOCKER_TAG}"; args "-u jenkins --runtime=sysbox-runc -e RUN_DOCKER=1"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment {
                        MAVEN_PROJECTS = "server"
                        DRUID_USE_DEFAULT_VALUE_FOR_NULL = "false"
                    }
                    steps { runUnitTest() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage('(openjdk11) other modules test') {
                    agent { docker { image "${IMAGE_JDK11}-${DOCKER_TAG}"; args "-u jenkins --runtime=sysbox-runc -e RUN_DOCKER=1"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment {
                        MAVEN_PROJECTS = "!processing,!indexing-hadoop,!indexing-service,!extensions-core/kafka-indexing-service,!extensions-core/kinesis-indexing-service,!server,!web-console,!integration-tests,!processing,!indexing-hadoop,!indexing-service,!extensions-core/kafka-indexing-service,!extensions-core/kinesis-indexing-service,!server,!web-console,!integration-tests"
                        DRUID_USE_DEFAULT_VALUE_FOR_NULL = "true"
                    }
                    steps { runUnitTest() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage('(openjdk11) other modules test (SQL Compatibility)') {
                    agent { docker { image "${IMAGE_JDK11}-${DOCKER_TAG}"; args "-u jenkins --runtime=sysbox-runc -e RUN_DOCKER=1"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment {
                        MAVEN_PROJECTS = "!processing,!indexing-hadoop,!indexing-service,!extensions-core/kafka-indexing-service,!extensions-core/kinesis-indexing-service,!server,!web-console,!integration-tests,!processing,!indexing-hadoop,!indexing-service,!extensions-core/kafka-indexing-service,!extensions-core/kinesis-indexing-service,!server,!web-console,!integration-tests"
                        DRUID_USE_DEFAULT_VALUE_FOR_NULL = "false"
                    }
                    steps { runUnitTest() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                // example of integration tests stage:
                stage('(Compile=openjdk8, Run=openjdk8) imply query integration tests') {
                    agent {
                        docker {
                            image "${IMAGE_JDK8}-${DOCKER_TAG}"
                            args "${DOCKER_AGENT_ARGS}"
                            registryUrl "${RT_REGISTRY_URL}"
                            registryCredentialsId "${RT_REGISTRY_CREDS}"
                            label "${DOCKER_AGENT_LABEL}"
                        }
                    }
                    steps {
                        // integration tests here:
                        // jvm runtime is specified here:
                        implyQueryIntegrationTests('-Djvm.runtime=8')
                    }
                    post {
                        // collect artifacts (docker logs and task logs):
                        always { buildArtifacts(env.STAGE_NAME) }
                        // clean untracked files from cloned repo:
                        cleanup { resetWs() }
                    }
                }

                // here is short format of integration tests stage:
                stage('(Compile=openjdk8, Run=openjdk8) imply keycloak security integration tests') {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    steps { implyKeycloakSecurityIntegrationTests('-Djvm.runtime=8') }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage('(Compile=openjdk8, Run=openjdk8) imply cold tier integration tests') {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    steps { implyVirtualSegmentsIntegrationTests('-Djvm.runtime=8') }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage('(Compile=openjdk8, Run=openjdk8) imply async query result download integration tests') {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    steps { implyAsyncDownloadIntegrationTests('-Djvm.runtime=8') }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage('(Compile=openjdk8, Run=openjdk8) imply s3 tests') {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    steps { implyS3Tests('-Djvm.runtime=8') }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage('(Compile=openjdk8, Run=openjdk8) s3 deep storage test') {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    steps { s3DeepStorageTests('-Djvm.runtime=8') }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage('(Compile=openjdk8, Run=openjdk8) azure deep storage test') {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    steps { azureDeepStorageTests('-Djvm.runtime=8') }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage('(Compile=openjdk8, Run=openjdk8) hdfs deep storage test') {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    steps { hdfsDeepStorageTests('-Djvm.runtime=8') }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage('(Compile=openjdk8, Run=openjdk8) gcs deep storage test') {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    steps { gcsDeepStorageTests('-Djvm.runtime=8') }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage('(Compile=openjdk8, Run=openjdk8) kinesis deep storage test') {
                    when {
                        expression { "disabling in monthly/master and added it to monthly-flaky-tests"  == "OK" }
                    }
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    steps { kinesisDeepStorageTests('-Djvm.runtime=8') }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                // -Djvm.runtime=11

                stage("(Compile=openjdk8, Run=openjdk11) query integration test") {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment { TESTNG_GROUPS = '-Dgroups=query'; JVM_RUNTIME = '-Djvm.runtime=11';
                        USE_INDEXER = 'middleManager'; }
                    steps { coreIntegrationTestsWithPrepopulatedData() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage('(Compile=openjdk8, Run=openjdk11) imply query integration tests') {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    steps { implyQueryIntegrationTests('-Djvm.runtime=11') }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage("(Compile=openjdk8, Run=openjdk11) query error integration test for missing segments") {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment { TESTNG_GROUPS = '-Dgroups=query-error'; JVM_RUNTIME = '-Djvm.runtime=11';
                        USE_INDEXER = 'middleManager'; }
                    steps { coreIntegrationTestsWithPrepopulatedData() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage('(Compile=openjdk8, Run=openjdk11) imply keycloak security integration tests') {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    steps { implyKeycloakSecurityIntegrationTests('-Djvm.runtime=11') }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage('(Compile=openjdk8, Run=openjdk11) s3 deep storage test') {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    steps { s3DeepStorageTests('-Djvm.runtime=11') }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage('(Compile=openjdk8, Run=openjdk11) azure deep storage test') {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    steps { azureDeepStorageTests('-Djvm.runtime=11') }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage('(Compile=openjdk8, Run=openjdk11) hdfs deep storage test') {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    steps { hdfsDeepStorageTests('-Djvm.runtime=11') }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage('(Compile=openjdk8, Run=openjdk11) gcs deep storage test') {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    steps { gcsDeepStorageTests('-Djvm.runtime=11') }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                // core integration tests

                stage("(Compile=openjdk8, Run=openjdk8) batch index integration test") {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment { TESTNG_GROUPS = '-Dgroups=batch-index'; JVM_RUNTIME = '-Djvm.runtime=8';
                        USE_INDEXER = 'middleManager'; }
                    steps { coreIntegrationTests() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage("(Compile=openjdk8, Run=openjdk8) batch index integration test with Indexer") {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment { TESTNG_GROUPS = '-Dgroups=batch-index'; JVM_RUNTIME = '-Djvm.runtime=8';
                        USE_INDEXER = 'indexer'; }
                    steps { coreIntegrationTests() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage("(Compile=openjdk8, Run=openjdk8) input format integration test") {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment { TESTNG_GROUPS = '-Dgroups=input-format'; JVM_RUNTIME = '-Djvm.runtime=8';
                        USE_INDEXER = 'middleManager'; }
                    steps { coreIntegrationTests() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage("(Compile=openjdk8, Run=openjdk8) input format integration test with Indexer") {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment { TESTNG_GROUPS = '-Dgroups=input-format'; JVM_RUNTIME = '-Djvm.runtime=8';
                        USE_INDEXER = 'indexer'; }
                    steps { coreIntegrationTests() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage("(Compile=openjdk8, Run=openjdk8) input source integration test") {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment { TESTNG_GROUPS = '-Dgroups=input-source'; JVM_RUNTIME = '-Djvm.runtime=8';
                        USE_INDEXER = 'middleManager'; }
                    steps { coreIntegrationTests() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage("(Compile=openjdk8, Run=openjdk8) input source integration test with Indexer") {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment { TESTNG_GROUPS = '-Dgroups=input-source'; JVM_RUNTIME = '-Djvm.runtime=8';
                        USE_INDEXER = 'indexer'; }
                    steps { coreIntegrationTests() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage("(Compile=openjdk8, Run=openjdk8) perfect rollup parallel batch index integration test") {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment { TESTNG_GROUPS = '-Dgroups=perfect-rollup-parallel-batch-index';
                        JVM_RUNTIME = '-Djvm.runtime=8'; USE_INDEXER = 'middleManager'; }
                    steps { coreIntegrationTests() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage("(Compile=openjdk8, Run=openjdk8) perfect rollup parallel batch index integration test with Indexer") {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment { TESTNG_GROUPS = '-Dgroups=perfect-rollup-parallel-batch-index';
                        JVM_RUNTIME = '-Djvm.runtime=8'; USE_INDEXER = 'indexer'; }
                    steps { coreIntegrationTests() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage("(Compile=openjdk8, Run=openjdk8) perfect rollup parallel batch index integration test with deep storage as intermediate store") {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment { TESTNG_GROUPS = '-Dgroups=shuffle-deep-store';
                        JVM_RUNTIME = '-Djvm.runtime=8'; USE_INDEXER = 'middleManager'; }
                    steps { coreIntegrationTestsWithShuffleDeepStorage() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage("(Compile=openjdk8, Run=openjdk8) perfect rollup parallel batch index integration test with deep storage as intermediate store with indexer") {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment { TESTNG_GROUPS = '-Dgroups=shuffle-deep-store';
                        JVM_RUNTIME = '-Djvm.runtime=8'; USE_INDEXER = 'indexer'; }
                    steps { coreIntegrationTestsWithShuffleDeepStorage() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage("(Compile=openjdk8, Run=openjdk8) kafka index integration test") {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment { TESTNG_GROUPS = '-Dgroups=kafka-index'; JVM_RUNTIME = '-Djvm.runtime=8';
                        USE_INDEXER = 'middleManager'; }
                    steps { coreIntegrationTests() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage("(Compile=openjdk8, Run=openjdk8) kafka index, transactional kafka index integration test with Indexer") {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment { TESTNG_GROUPS = '-Dgroups=kafka-index,kafka-transactional-index';
                        JVM_RUNTIME = '-Djvm.runtime=8'; USE_INDEXER = 'indexer'; }
                    steps { coreIntegrationTests() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage("(Compile=openjdk8, Run=openjdk8) kafka index integration test slow") {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment { TESTNG_GROUPS = '-Dgroups=kafka-index-slow'; JVM_RUNTIME = '-Djvm.runtime=8';
                        USE_INDEXER = 'middleManager'; }
                    steps { coreIntegrationTests() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage("(Compile=openjdk8, Run=openjdk8) kafka index integration test slow with Indexer") {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment { TESTNG_GROUPS = '-Dgroups=kafka-index-slow'; JVM_RUNTIME = '-Djvm.runtime=8';
                        USE_INDEXER = 'indexer'; }
                    steps { coreIntegrationTests() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage("(Compile=openjdk8, Run=openjdk8) transactional kafka index integration test") {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment { TESTNG_GROUPS = '-Dgroups=kafka-transactional-index';
                        JVM_RUNTIME = '-Djvm.runtime=8'; USE_INDEXER = 'middleManager'; }
                    steps { coreIntegrationTests() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage("(Compile=openjdk8, Run=openjdk8) transactional kafka index integration test slow") {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment { TESTNG_GROUPS = '-Dgroups=kafka-transactional-index-slow';
                        JVM_RUNTIME = '-Djvm.runtime=8'; USE_INDEXER = 'middleManager'; }
                    steps { coreIntegrationTests() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage("(Compile=openjdk8, Run=openjdk8) transactional kafka index integration test slow with Indexer") {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment { TESTNG_GROUPS = '-Dgroups=kafka-transactional-index-slow';
                        JVM_RUNTIME = '-Djvm.runtime=8'; USE_INDEXER = 'indexer'; }
                    steps { coreIntegrationTests() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage("(Compile=openjdk8, Run=openjdk8) Kafka index integration test with various formats") {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment { TESTNG_GROUPS = '-Dgroups=kafka-data-format'; JVM_RUNTIME = '-Djvm.runtime=8';
                        USE_INDEXER = 'middleManager'; }
                    steps { coreIntegrationTests() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage("(Compile=openjdk8, Run=openjdk8) Kafka index integration test with various formats with Indexer") {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment { TESTNG_GROUPS = '-Dgroups=kafka-data-format'; JVM_RUNTIME = '-Djvm.runtime=8';
                        USE_INDEXER = 'indexer'; }
                    steps { coreIntegrationTests() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage("(Compile=openjdk8, Run=openjdk8) query integration test") {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment { TESTNG_GROUPS = '-Dgroups=query'; JVM_RUNTIME = '-Djvm.runtime=8';
                        USE_INDEXER = 'middleManager'; }
                    steps { coreIntegrationTestsWithPrepopulatedData() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage("(Compile=openjdk8, Run=openjdk8) query error integration test") {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment { TESTNG_GROUPS = '-Dgroups=query-error'; JVM_RUNTIME = '-Djvm.runtime=8';
                        USE_INDEXER = 'middleManager'; }
                    steps { coreIntegrationTestsWithPrepopulatedData() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage("(Compile=openjdk8, Run=openjdk8) query retry integration test for missing segments") {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment { TESTNG_GROUPS = '-Dgroups=query-retry'; JVM_RUNTIME = '-Djvm.runtime=8';
                        USE_INDEXER = 'middleManager'; }
                    steps { coreIntegrationTestsWithPrepopulatedData() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage("(Compile=openjdk8, Run=openjdk8) security integration test") {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment { TESTNG_GROUPS = '-Dgroups=security'; JVM_RUNTIME = '-Djvm.runtime=8';
                        USE_INDEXER = 'middleManager'; }
                    steps { coreIntegrationTestsWithPrepopulatedData() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage("(Compile=openjdk8, Run=openjdk8) ldap security integration test") {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment { TESTNG_GROUPS = '-Dgroups=ldap-security'; JVM_RUNTIME = '-Djvm.runtime=8';
                        USE_INDEXER = 'middleManager'; }
                    steps { coreIntegrationTests() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage("(Compile=openjdk8, Run=openjdk8) realtime index integration test") {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment { TESTNG_GROUPS = '-Dgroups=realtime-index'; JVM_RUNTIME = '-Djvm.runtime=8';
                        USE_INDEXER = 'middleManager'; }
                    steps { coreIntegrationTests() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage("(Compile=openjdk8, Run=openjdk8) append ingestion integration test") {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment { TESTNG_GROUPS = '-Dgroups=append-ingestion'; JVM_RUNTIME = '-Djvm.runtime=8';
                        USE_INDEXER = 'middleManager'; }
                    steps { coreIntegrationTests() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage("(Compile=openjdk8, Run=openjdk8) append ingestion integration test with Indexer") {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment { TESTNG_GROUPS = '-Dgroups=append-ingestion'; JVM_RUNTIME = '-Djvm.runtime=8';
                        USE_INDEXER = 'indexer'; }
                    steps { coreIntegrationTests() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage("(Compile=openjdk8, Run=openjdk8) compaction integration test") {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment { TESTNG_GROUPS = '-Dgroups=compaction'; JVM_RUNTIME = '-Djvm.runtime=8';
                        USE_INDEXER = 'middleManager'; }
                    steps { coreIntegrationTests() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage("(Compile=openjdk8, Run=openjdk8) compaction integration test with Indexer") {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment { TESTNG_GROUPS = '-Dgroups=compaction'; JVM_RUNTIME = '-Djvm.runtime=8';
                        USE_INDEXER = 'indexer'; }
                    steps { coreIntegrationTests() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage("(Compile=openjdk8, Run=openjdk8) other integration tests") {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment {
                        TESTNG_GROUPS = '-DexcludedGroups=batch-index,input-format,input-source,perfect-rollup-parallel-batch-index,kafka-index,query,query-retry,realtime-index,security,ldap-security,s3-deep-storage,gcs-deep-storage,azure-deep-storage,hdfs-deep-storage,s3-ingestion,kinesis-index,kinesis-data-format,kafka-transactional-index,kafka-index-slow,kafka-transactional-index-slow,kafka-data-format,hadoop-s3-to-s3-deep-storage,hadoop-s3-to-hdfs-deep-storage,hadoop-azure-to-azure-deep-storage,hadoop-azure-to-hdfs-deep-storage,hadoop-gcs-to-gcs-deep-storage,hadoop-gcs-to-hdfs-deep-storage,aliyun-oss-deep-storage,append-ingestion,compaction,high-availability,upgrade,query-error,shuffle-deep-store,custom-coordinator-duties,async-download'
                        JVM_RUNTIME = '-Djvm.runtime=8'
                        USE_INDEXER = 'middleManager'
                    }
                    steps { coreIntegrationTests() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage("(Compile=openjdk8, Run=openjdk8) other integration tests with Indexer") {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment {
                        TESTNG_GROUPS = '-DexcludedGroups=batch-index,input-format,input-source,perfect-rollup-parallel-batch-index,kafka-index,query,query-retry,realtime-index,security,ldap-security,s3-deep-storage,gcs-deep-storage,azure-deep-storage,hdfs-deep-storage,s3-ingestion,kinesis-index,kinesis-data-format,kafka-transactional-index,kafka-index-slow,kafka-transactional-index-slow,kafka-data-format,hadoop-s3-to-s3-deep-storage,hadoop-s3-to-hdfs-deep-storage,hadoop-azure-to-azure-deep-storage,hadoop-azure-to-hdfs-deep-storage,hadoop-gcs-to-gcs-deep-storage,hadoop-gcs-to-hdfs-deep-storage,aliyun-oss-deep-storage,append-ingestion,compaction,high-availability,upgrade,query-error,shuffle-deep-store,custom-coordinator-duties,async-download'
                        JVM_RUNTIME = '-Djvm.runtime=8'
                        USE_INDEXER = 'indexer'
                    }
                    steps { coreIntegrationTests() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage("(Compile=openjdk8, Run=openjdk8) leadership and high availability integration tests") {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment { TESTNG_GROUPS = '-Dgroups=high-availability'; JVM_RUNTIME = '-Djvm.runtime=8';
                        USE_INDEXER = 'middleManager'; }
                    steps { coreIntegrationTestsWithPrepopulatedData() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }

                stage("(Compile=openjdk8, Run=openjdk11) ldap security integration test") {
                    agent { docker { image "${IMAGE_JDK8}-${DOCKER_TAG}"; args "${DOCKER_AGENT_ARGS}"; registryUrl "${RT_REGISTRY_URL}"; registryCredentialsId "${RT_REGISTRY_CREDS}"; label "${DOCKER_AGENT_LABEL}" } }
                    environment { TESTNG_GROUPS = '-Dgroups=ldap-security'; JVM_RUNTIME = '-Djvm.runtime=11';
                        USE_INDEXER = 'middleManager'; }
                    steps { coreIntegrationTests() }
                    post { always { buildArtifacts(env.STAGE_NAME) }; cleanup { resetWs() } }
                }
            } // end of parallel
        } // end of stage('Checks')

        stage("Tag verified builds") {
            when {
                anyOf {
                    expression { (env.CHANGE_BRANCH ?: env.BRANCH_NAME) ==~ env.ACTIVE_DEV_BRANCH_REGEX }
                    expression { (env.CHANGE_BRANCH ?: env.BRANCH_NAME) ==~ (env.RELEASE_BRANCH_PREFIX_REGEX + env.RELEASE_BRANCH_SUFFIX_REGEX) }
                    expression { params.PUBLISH_ON_ANY_BRANCH }
                }
                beforeAgent true
            }

            matrix {
                axes {
                    axis {
                        name 'BUILD_PROFILE'
                        values 'dist', 'imply-saas', 'imply-experimental'
                    }
                }
                stages {
                    stage('profile tag BVT Pass') {
                        environment {
                            GIT_ASKPASS = "/tmp/askpass.sh"
                            GITHUB_NETRC = "/tmp/github-netrc"
                            STAGING_BASE_DIR= "/tmp/druid-build/stage"
                            TMP_DIR = "/tmp/druid-build/tmp"
                            BUILD_DIR = "/tmp/druid-build"
                            ARTIFACT_NAME = sh(script:"""#!/bin/bash
                                if [ "${BUILD_PROFILE}" == "imply-saas" ]; then
                                    echo "druid-saas"
                                elif [ "${BUILD_PROFILE}" == "imply-experimental" ]; then
                                    echo "druid-experimental"
                                else
                                    echo "druid"
                                fi
                            """, returnStdout: true).trim()
                        }
                        agent {
                            docker {
                                image 'docker/buildabear:20200923'
                                args '-u root:root'
                                label "${DOCKER_AGENT_LABEL}"
                                registryUrl "${RT_REGISTRY_URL}"
                                registryCredentialsId "${RT_REGISTRY_CREDS}"
                            }
                        }
                        stages {
                            stage('Set jenkins-verified property') {
                                steps {
                                    script {
                                        def release_version = "None"
                                        def headBranch = env.CHANGE_BRANCH ?: env.BRANCH_NAME
                                        if(headBranch ==~ (env.RELEASE_BRANCH_PREFIX_REGEX + env.RELEASE_BRANCH_SUFFIX_REGEX)) {
                                            release_version = (headBranch =~ env.RELEASE_BRANCH_SUFFIX_REGEX).getAt(0)
                                        } else if(headBranch ==~ env.ACTIVE_DEV_BRANCH_REGEX) {
                                            release_version = sh(
                                                    script: '''#!/bin/bash -e
                                                    curl -s --netrc-file ${GITHUB_NETRC} \
                                                    -H "Accept: application/vnd.github.v3.raw" \
                                                    https://api.github.com/repos/implydata/imply-release/contents/monthly-release.version |  \
                                                    tee /dev/stderr
                                                ''',
                                                    returnStdout: true
                                            ).trim()
                                        }
                                        echo "setting BVT=Pass for tgz-local/${ARTIFACT_NAME}/${ARTIFACT_NAME}-${BUILD_VERSION}.tar.gz"
                                        rtSetProps (
                                                serverId: "${RT_SERVER_ID}",
                                                spec: """{
                                                "files": [
                                                    {
                                                      "pattern": "tgz-local/${ARTIFACT_NAME}/${ARTIFACT_NAME}-${BUILD_VERSION}.tar.gz",
                                                      "props": "BVT=InProgress"
                                                    }
                                                ]
                                            }""",
                                                props: 'BVT=Pass',
                                                failNoOp: true
                                        )
                                    }
                                }
                            } // end of stage('Set BVT=pass property')
                        } // end of stages
                        post {
                            cleanup {
                                resetWs()
                            }
                        }
                    } // end of stage('profile build and upload')
                } // end of stages
            } // end of matrix
        } // end of stage("Tag verified builds")
    } // end of stages
    post {
        failure {
            script {
                if(isEligibleToNotify()) {
                    library 'imply-shared-library'
                    failedDruidBVTNotification(currentBuild)
                }
            }
            node('jenkinsOnDemand'){
                // notify about failed build
                script {
                    echo "checking to see if should set BVT as Fail for ${BUILD_VERSION}"
                    if (env.BUILD_UPLOAD_SUCCESS == null || !env.BUILD_UPLOAD_SUCCESS) {
                        echo "Not setting BVT as Fail"
                        return
                    }
                    echo "Setting BVT as Fail"
                    markBvtAsFail('druid', "${BUILD_VERSION}")
                    markBvtAsFail('druid-saas', "${BUILD_VERSION}")
                    markBvtAsFail('druid-experimental', "{$BUILD_VERSION}")
                }
            }
        }
        success {
            // notify about fixed build
            script {
                if(isEligibleToNotify()) {
                    library 'imply-shared-library'
                    fixedDruidBVTNotification(currentBuild)
                }
            }
        }
    }
}

